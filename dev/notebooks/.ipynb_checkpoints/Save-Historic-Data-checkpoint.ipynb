{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbpro as gdax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from math import ceil\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline\n",
    "client = gdax.PublicClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historic_data(client, product, num_candles, granularity, max_per=300):\n",
    "    now = datetime.utcnow().replace(microsecond=0).replace(second=0)\n",
    "    unit = timedelta(seconds=granularity)\n",
    "    begin = now - (num_candles * unit)\n",
    "    delta = unit * max_per\n",
    "    full = ceil(num_candles / max_per)\n",
    "    rates = []\n",
    "    for i in range(0,full):\n",
    "        frm = begin + (delta * i)\n",
    "        to  = frm + delta\n",
    "        chunk = client.get_product_historic_rates(\n",
    "            product, start=frm.isoformat(), end=to.isoformat(), granularity=granularity)\n",
    "        if type(chunk) is not list:\n",
    "            print(chunk)\n",
    "        else:\n",
    "            rates.extend(chunk)\n",
    "            print('From: {}, To: {} - {} points'.format(frm.isoformat(), to.isoformat(), len(chunk)))\n",
    "        sleep(0.6)\n",
    "    return rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rates(product, num_candles=None, granularity=60):\n",
    "    rates = historic_data(client=client, product=product, num_candles=num_candles, granularity=granularity)\n",
    "    print('{} prices'.format(len(rates)))\n",
    "    # Load into Pandas\n",
    "    pd_rates = pd.DataFrame(rates)\n",
    "    # Set column names\n",
    "    pd_rates.columns = [\"Time\", \"Low\", \"High\", \"Open\", \"Close\", \"Volume\"]\n",
    "    # Convert Unix time to UTC\n",
    "    pd_rates[\"Time\"] = pd.to_datetime(pd_rates[\"Time\"],unit='s')\n",
    "    # Remove duplicates\n",
    "    before = len(pd_rates)\n",
    "    pd_rates.drop_duplicates(inplace=True)\n",
    "    print(\"Dropped {} duplicate rows\".format(before - len(pd_rates)))\n",
    "    print(pd_rates.head())\n",
    "    # Save to CSV\n",
    "    fn = \"./historic_data/{}_{}_{}.csv\".format(product, granularity, len(pd_rates))\n",
    "    pd_rates.to_csv(fn, index=False)\n",
    "    return pd_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n",
      "LTC-USD\n",
      "ETC-USD\n",
      "ZRX-USD\n"
     ]
    }
   ],
   "source": [
    "prods_top_save\n",
    "all_prods = client.get_products()\n",
    "for prod in all_prods:\n",
    "    prod_str = prod['id']\n",
    "    if 'USD' in prod_str and 'USDC' not in prod_str:\n",
    "        print(prod_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = client.get_products()\n",
    "for prod in prods:\n",
    "    prod_id = prod['id']\n",
    "    print(\"Downloading data for {}\".format(prod_id))\n",
    "    save_rates(prod_id, granularity=60, num_candles=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
